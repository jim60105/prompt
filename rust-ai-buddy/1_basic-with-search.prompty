---
name: Rust AI Buddy
description: |
  🤖 遇見你的最佳 Rust 助手 — Rust AI Buddy！
  💻 我能夠即時解答你的 Rust 相關問題，提供程式碼優化建議，並協助你快速掌握這門強大的程式語言。
  🚀 無論你是初學者還是經驗豐富的開發者，Rust AI Buddy 都將成為你 Coding 之旅中不可或缺的得力助手！
model:
  configuration:
    name: claude-3-5-sonnet-latest
sample:
  BOT_USER_INPUT: |
    我正在使用 tokio，如何立即執行 future，並在執行下一行之前等待它?
  knowledge: |
    [
    {
        "output": "URL: https://crows.land/tldextract-rs/tokio/runtime/struct.Runtime.html\nTITLE: tokio::runtime::Runtime - Rust\nCONTENT: Create a new runtime instance with default configuration values.\nThis results in a reactor, thread pool, and timer being initialized. The\nthread pool will not spawn any worker threads until it needs to, i.e.\ntasks are scheduled to run.\nMost users will not need to call this function directly, instead they\nwill use tokio::run.\nSee module level documentation for more details.\n\nCreating a new Runtime with default configuration values.\n\nuse tokio::runtime::Runtime;\nuse tokio::prelude::*;\n\nlet rt = Runtime::new()\n    .unwrap();\n\n\n\n\nrt.shutdown_now()\n    .wait().unwrap();\nReturn a reference to the reactor handle for this runtime instance.\nThe returned handle reference can be cloned in order to get an owned\nvalue of the handle. This handle can be used to initialize I/O resources\n(like TCP or UDP sockets) that will not be used on the runtime.\n\nuse tokio::runtime::Runtime;\n\nlet rt = Runtime::new()\n    .unwrap();\n\nlet reactor_handle = rt.reactor().clone();\n\n\nReturn a handle to the runtime's executor.\nThe returned handle can be used to spawn tasks that run on this runtime.\n\nuse tokio::runtime::Runtime;\n\nlet rt = Runtime::new()\n    .unwrap();\n\nlet executor_handle = rt.executor();\n\n\nSpawn a future onto the Tokio runtime.\nThis spawns the given future onto the runtime's executor, usually a\nthread pool. The thread pool is then responsible for polling the future\nuntil it completes.\nSee module level documentation for more details.\n\nuse tokio::runtime::Runtime;\n\n\nlet mut rt = Runtime::new().unwrap();\n\n\nrt.spawn(future::lazy(|| {\n    println!(\"now running on a worker thread\");\n    Ok(())\n}));\n\nThis function panics if the spawn fails. Failure occurs if the executor\nis currently at capacity and is unable to spawn a new future.\npub fn block_on<F, R, E>(&mut self, future: F) -> Result<R, E> where    F: Send + 'static + Future<Item = R, Error = E>,    R: Send + 'static,    E: Send + 'static, [src]Run a future to completion on the Tokio runtime.\nThis runs the given future on the runtime, blocking until it is\ncomplete, and yielding its resolved result. Any tasks or timers which\nthe future spawns internally will be executed on the runtime.\nThis method should not be called from an asynchrounous context.\n\nThis function panics if the executor is at capacity, if the provided\nfuture panics, or if called within an asynchronous execution context.\nRun a future to completion on the Tokio runtime, then wait for all\nbackground futures to complete too.\nThis runs the given future on the runtime, blocking until it is\ncomplete, waiting for background futures to complete, and yielding\nits resolved result. Any tasks or timers which the future spawns\ninternally will be executed on the runtime and waited for completion.\nThis method should not be called from an asynchrounous context.\n\nThis function panics if the executor is at capacity, if the provided\nfuture panics, or if called within an asynchronous execution context.\nSignals the runtime to shutdown once it becomes idle.\nReturns a future that completes once the shutdown operation has\ncompleted.\nThis function can be used to perform a graceful shutdown of the runtime.\nThe runtime enters an idle state once all of the following occur.\n\nThe thread pool has no tasks to execute, i.e., all tasks that were\nspawned have completed.\nThe reactor is not managing any I/O resources.\n\nSee module level documentation for more details.\n\nuse tokio::runtime::Runtime;\nuse tokio::prelude::*;\n\nlet rt = Runtime::new()\n    .unwrap();\n\n\n\n\nrt.shutdown_on_idle()\n    .wait().unwrap();\nSignals the runtime to shutdown immediately.\nReturns a future that completes once the shutdown operation has\ncompleted.\nThis function will forcibly shutdown the runtime, causing any\nin-progress work to become canceled. The shutdown steps are:\n\nDrain any scheduled work queues.\nDrop any futures that have not yet completed.\nDrop the reactor.\n\nOnce the reactor has dropped, any outstanding I/O resources bound to\nthat reactor will no longer function. Calling any method on them will\nresult in an error.\nSee module level documentation for more details.\n\nuse tokio::runtime::Runtime;\nuse tokio::prelude::*;\n\nlet rt = Runtime::new()\n    .unwrap();\n\n\n\n\nrt.shutdown_now()\n    .wait().unwrap();\n"
    },
    {
        "output": "URL: https://tokio-cn.github.io/docs/getting-started/futures/\nTITLE: async fn · Tokio 中文站\nCONTENT: \n      \n      \n      \n\nLet’s take a closer look at Rust’s async fn feature. Tokio is built on top of\nRust’s asynchronous model. This allows Tokio to interop with other libraries\nalso using the futures crate.\n\nNote: This runtime model is very different than async libraries found in\nother languages. While, at a high level, APIs can look similar, the way code\ngets executed differs.\n\nWe’ll be taking a closer look at the runtime in the upcoming sections, but a\nbasic understanding of the runtime is necessary to understand futures. To gain\nthis understanding, we’ll first look at the synchronous model that Rust uses by\ndefault and see how this differs from Tokio’s asynchronous model.\n\nSynchronous Model\n\nFirst, let’s talk briefly about the synchronous (or blocking) model that the\nRust standard library uses.\n\n# use std::io::prelude::*;\n# use std::net::TcpStream;\n# fn main() {\nlet mut socket = TcpStream::connect(\"127.0.0.1:8080\").unwrap();\nlet mut buf = [0; 1024];\nlet n = socket.read(&mut buf).unwrap();\n\n// Do something with &buf[..n];\n# drop(n);\n# }\n\n\nWhen socket.read is called, either the socket has pending data in its receive\nbuffer or it does not. If there is pending data, the call to read will return\nimmediately and buf will be filled with that data. However, if there is no\npending data, the read function will block the current thread until data is\nreceived. Once the data is received, buf will be filled with this newly received\ndata and the read function will return.\n\nIn order to perform reads on many different sockets concurrently, a thread per\nsocket is required. Using a thread per socket does not scale up very well to\nlarge numbers of sockets. This is known as the c10k problem.\n\nNon-blocking sockets\n\nThe way to avoid blocking a thread when performing an operation like read is to\nnot block the thread! Non-blocking sockets allow performing operations, like read,\nwithout blocking the thread. When the socket has no pending data in its receive\nbuffer, the read function returns immediately, indicating that the socket was “not\nready” to perform the read operation.\n\nWith non-blocking sockets, instead of blocking the thread and waiting on data to\narrive, the thread is able to perform other work. Once data arrives on the\nsocket, the operating system sends a notification to the process, the process\ntries to read from the socket again, and this time, there is data.\n\nThis I/O model is provided by mio, a low level, non-blocking I/O library for\nRust. The problem with using Mio is that applications written to use Mio\ndirectly tend to require a high amount of complexity. The application must\nmaintain large state machines tracking the state in which the application\ncurrently is in. Once an operating system notification arrives, the application\ntakes action (tries to read from a socket) and updates its state accordingly.\n\nasync fn\n\nRust’s async fn feature allows the programmer to write their application using\nsynchronous logic flow: the flow of the code matches the flow of execution, i.e.\nsimilar to writing synchronous code. The compiler will then transform the code\nto generate the state machines needed to use non-blocking sockets.\n\nWhen calling an async fn, such as TcpStream::connect, instead of blocking\nthe current thread waiting for completion, a value representing the computation\nis immediately returned. This value implements the Future trait. There is no\nguarantee as to when or where the computation will happen. The computation may\nhappen immediately or it may be lazy (it usually is lazy). When the caller\nwishes to receive the result of the computation, .await is called on the\nfuture. The flow of execution stops until the Future completes and .await\nreturns the result.\n\nWhen the program is compiled, Rust finds all the .await calls and transforms\nthe async fn into a state machine (kind of like a big enum with a variant\nfor each .await).\n\nThe Tokio runtime is responsible for driving all the async fns in an\napplication to completion.\n\nA closer look at futures\n\nAs hinted above, async fn calls return instances of Future, but what is a\nfuture?\n\nA future is a value that represents the completion of an asynchronous\ncomputation. Usually, the future completes due to an event that happens\nelsewhere in the system (I/O event from the operating system, a timer elapsing,\nreceiving a message on a channel, …).\n\nAs hinted at earlier, the Rust asynchronous model is very different than that of\nother languages. Most other languages use a “completion” based model, usually\nbuilt using some form of callbacks. In this case, when an asynchronous action is\nstarted, it is submitted with a function to call once the operation completes.\nWhen the process receives the I/O notification from the operating system, it\nfinds the function associated with it and calls it immediately. This is a\npush based model because the value is pushed into the callback.\n\nThe rust asynchronous model is pull based. Instead of a Future\nbeing responsible for pushing the data into a callback, it relies on something\nelse asking if it is complete or not. In the case of Tokio, that something\nelse is the Tokio runtime.\n\nUsing a poll based model offers many advantages, including being a zero cost\nabstraction, i.e., using Rust futures has no added overhead compared to writing\nthe asynchronous code by hand.\n\nWe’ll take a closer look at this poll based model in the next section.\n\nThe Future trait\n\nThe Future trait is as follows:\n\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\npub trait Future {\n    /// The type of value produced on completion.\n    type Output;\n\n    /// Attempt to resolve the future to a final value, registering\n    /// the current task for wakeup if the value is not yet available.\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output>;\n}\n# fn main() {}\n\n\nFor now it’s just important to know that futures have an associated type,\nOutput, which is the type yielded when the future completes. The poll\nfunction is the function that the Tokio runtime calls to check if the future is\ncomplete.\n\n      \n      \n        \n      \n    "
    },
    {
        "output": "URL: https://github.com/tokio-rs/tokio/discussions/5369\nTITLE: How to wait for all tasks to finish executing · tokio-rs/tokio · Discussion #5369\nCONTENT: \n    \n        \n    \n        Code:\nuse tokio::time::{sleep, Duration};\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    tokio::spawn(async move {\n        sleep(Duration::from_millis(1000)).await;\n        println!(\"OK\");\n    });\n    Ok(())\n}\nNo output after running.\nI don't want to use join! myself, because I have some logic that will be executed by calling tokio::spawn() directly.\nI think there should be a way to wait for all tasks to finish executing, but I didn't find in the documentation.\n    \n  \n\n    \n  "
    },
    {
        "output": "URL: https://docs.rs/tokio/latest/tokio/runtime/struct.Runtime.html\nTITLE: Runtime in tokio::runtime - Rust\nCONTENT: pub struct Runtime { /* private fields */ }Available on crate feature rt only.Expand descriptionThe Tokio runtime.\nThe runtime provides an I/O driver, task scheduler, timer, and\nblocking pool, necessary for running asynchronous tasks.\nInstances of Runtime can be created using new, or Builder.\nHowever, most users will use the #[tokio::main] annotation on\ntheir entry point instead.\nSee module level documentation for more details.\n§Shutdown\nShutting down the runtime is done by dropping the value, or calling\nshutdown_background or shutdown_timeout.\nTasks spawned through Runtime::spawn keep running until they yield.\nThen they are dropped. They are not guaranteed to run to completion, but\nmight do so if they do not yield until completion.\nBlocking functions spawned through Runtime::spawn_blocking keep running\nuntil they return.\nThe thread initiating the shutdown blocks until all spawned work has been\nstopped. This can take an indefinite amount of time. The Drop\nimplementation waits forever for this.\nThe shutdown_background and shutdown_timeout methods can be used if\nwaiting forever is undesired. When the timeout is reached, spawned work that\ndid not stop in time and threads running it are leaked. The work continues\nto run until one of the stopping conditions is fulfilled, but the thread\ninitiating the shutdown is unblocked.\nOnce the runtime has been dropped, any outstanding I/O resources bound to\nit will no longer function. Calling any method on them will result in an\nerror.\n§Sharing\nThere are several ways to establish shared access to a Tokio runtime:\n\nUsing an Arc<Runtime>.\nUsing a Handle.\nEntering the runtime context.\n\nUsing an Arc<Runtime> or Handle allows you to do various\nthings with the runtime such as spawning new tasks or entering the runtime\ncontext. Both types can be cloned to create a new handle that allows access\nto the same runtime. By passing clones into different tasks or threads, you\nwill be able to access the runtime from those tasks or threads.\nThe difference between Arc<Runtime> and Handle is that\nan Arc<Runtime> will prevent the runtime from shutting down,\nwhereas a Handle does not prevent that. This is because shutdown of the\nruntime happens when the destructor of the Runtime object runs.\nCalls to shutdown_background and shutdown_timeout require exclusive\nownership of the Runtime type. When using an Arc<Runtime>,\nthis can be achieved via Arc::try_unwrap when only one strong count\nreference is left over.\nThe runtime context is entered using the Runtime::enter or\nHandle::enter methods, which use a thread-local variable to store the\ncurrent runtime. Whenever you are inside the runtime context, methods such\nas tokio::spawn will use the runtime whose context you are inside.\nSource§SourceAvailable on crate feature rt-multi-thread only.Creates a new runtime instance with default configuration values.\nThis results in the multi threaded scheduler, I/O driver, and time driver being\ninitialized.\nMost applications will not need to call this function directly. Instead,\nthey will use the  #[tokio::main] attribute. When a more complex\nconfiguration is necessary, the runtime builder may be used.\nSee module level documentation for more details.\n§Examples\nCreating a new Runtime with default configuration values.\n\nuse tokio::runtime::Runtime;\n\nlet rt = Runtime::new()\n    .unwrap();\n\n// Use the runtime...\nSourceReturns a handle to the runtime’s spawner.\nThe returned handle can be used to spawn tasks that run on this runtime, and can\nbe cloned to allow moving the Handle to other threads.\nCalling Handle::block_on on a handle to a current_thread runtime is error-prone.\nRefer to the documentation of Handle::block_on for more.\n§Examples\nuse tokio::runtime::Runtime;\n\nlet rt = Runtime::new()\n    .unwrap();\n\nlet handle = rt.handle();\n\n// Use the handle...\nSourceSpawns a future onto the Tokio runtime.\nThis spawns the given future onto the runtime’s executor, usually a\nthread pool. The thread pool is then responsible for polling the future\nuntil it completes.\nThe provided future will start running in the background immediately\nwhen spawn is called, even if you don’t await the returned\nJoinHandle.\nSee module level documentation for more details.\n§Examples\nuse tokio::runtime::Runtime;\n\n// Create the runtime\nlet rt = Runtime::new().unwrap();\n\n// Spawn a future onto the runtime\nrt.spawn(async {\n    println!(\"now running on a worker thread\");\n});\nSourceRuns the provided function on an executor dedicated to blocking operations.\n§Examples\nuse tokio::runtime::Runtime;\n\n// Create the runtime\nlet rt = Runtime::new().unwrap();\n\n// Spawn a blocking function onto the runtime\nrt.spawn_blocking(|| {\n    println!(\"now running on a worker thread\");\n});\nSourceRuns a future to completion on the Tokio runtime. This is the\nruntime’s entry point.\nThis runs the given future on the current thread, blocking until it is\ncomplete, and yielding its resolved result. Any tasks or timers\nwhich the future spawns internally will be executed on the runtime.\n§Non-worker future\nNote that the future required by this function does not run as a\nworker. The expectation is that other tasks are spawned by the future here.\nAwaiting on other futures from the future provided here will not\nperform as fast as those spawned as workers.\n§Multi thread scheduler\nWhen the multi thread scheduler is used this will allow futures\nto run within the io driver and timer context of the overall runtime.\nAny spawned tasks will continue running after block_on returns.\n§Current thread scheduler\nWhen the current thread scheduler is enabled block_on\ncan be called concurrently from multiple threads. The first call\nwill take ownership of the io and timer drivers. This means\nother threads which do not own the drivers will hook into that one.\nWhen the first block_on completes, other threads will be able to\n“steal” the driver to allow continued execution of their futures.\nAny spawned tasks will be suspended after block_on returns. Calling\nblock_on again will resume previously spawned tasks.\n§Panics\nThis function panics if the provided future panics, or if called within an\nasynchronous execution context.\n§Examples\nuse tokio::runtime::Runtime;\n\n// Create the runtime\nlet rt  = Runtime::new().unwrap();\n\n// Execute the future, blocking the current thread until completion\nrt.block_on(async {\n    println!(\"hello\");\n});\nSourceEnters the runtime context.\nThis allows you to construct types that must have an executor\navailable on creation such as Sleep or TcpStream. It will\nalso allow you to call methods such as tokio::spawn.\n§Example\nuse tokio::runtime::Runtime;\nuse tokio::task::JoinHandle;\n\nfn function_that_spawns(msg: String) -> JoinHandle<()> {\n    // Had we not used `rt.enter` below, this would panic.\n    tokio::spawn(async move {\n        println!(\"{}\", msg);\n    })\n}\n\nfn main() {\n    let rt = Runtime::new().unwrap();\n\n    let s = \"Hello World!\".to_string();\n\n    // By entering the context, we tie `tokio::spawn` to this executor.\n    let _guard = rt.enter();\n    let handle = function_that_spawns(s);\n\n    // Wait for the task before we end the test.\n    rt.block_on(handle).unwrap();\n}\nSourceShuts down the runtime, waiting for at most duration for all spawned\nwork to stop.\nSee the struct level documentation for more details.\n§Examples\nuse tokio::runtime::Runtime;\nuse tokio::task;\n\nuse std::thread;\nuse std::time::Duration;\n\nfn main() {\n   let runtime = Runtime::new().unwrap();\n\n   runtime.block_on(async move {\n       task::spawn_blocking(move || {\n           thread::sleep(Duration::from_secs(10_000));\n       });\n   });\n\n   runtime.shutdown_timeout(Duration::from_millis(100));\n}\nSourceShuts down the runtime, without waiting for any spawned work to stop.\nThis can be useful if you want to drop a runtime from within another runtime.\nNormally, dropping a runtime will block indefinitely for spawned blocking tasks\nto complete, which would normally not be permitted within an asynchronous context.\nBy calling shutdown_background(), you can drop the runtime from such a context.\nNote however, that because we do not wait for any blocking tasks to complete, this\nmay result in a resource leak (in that any blocking tasks are still running until they\nreturn.\nSee the struct level documentation for more details.\nThis function is equivalent to calling shutdown_timeout(Duration::from_nanos(0)).\n\nuse tokio::runtime::Runtime;\n\nfn main() {\n   let runtime = Runtime::new().unwrap();\n\n   runtime.block_on(async move {\n       let inner_runtime = Runtime::new().unwrap();\n       // ...\n       inner_runtime.shutdown_background();\n   });\n}\nSourceReturns a view that lets you get information about how the runtime\nis performing.§§§§"
    },
    {
        "output": "URL: https://v0-1--tokio.netlify.app/docs/futures/basic/\nTITLE: Implementing futures · Tokio\nCONTENT: \n      \n      \n      \n\nImplementing futures is very common when using Tokio. Let’s start with a very\nbasic future that performs no asynchronous logic and simply returns a message\n(the venerable “hello world”).\n\nThe Future trait.\n\nThe Future trait is as follows:\n\ntrait Future {\n    /// The type of the value returned when the future completes.\n    type Item;\n\n    /// The type representing errors that occurred while processing the computation.\n    type Error;\n\n    /// The function that will be repeatedly called to see if the future\n    /// has completed or not. The `Async` enum can either be `Ready` or\n    /// `NotReady` and indicates whether the future is ready to produce\n    /// a value or not.\n    fn poll(&mut self) -> Result<Async<Self::Item>, Self::Error>;\n}\n\n\nLet’s implement it for our “hello world” future:\n\n# #![deny(deprecated)]\nextern crate futures;\n\n// `Poll` is a type alias for `Result<Async<T>, E>`\nuse futures::{Future, Async, Poll};\n\nstruct HelloWorld;\n\nimpl Future for HelloWorld {\n    type Item = String;\n    type Error = ();\n\n    fn poll(&mut self) -> Poll<Self::Item, Self::Error> {\n        Ok(Async::Ready(\"hello world\".to_string()))\n    }\n}\n\n# fn main() {}\n\n\nThe Item and Error associated types define the types returned by the future\nonce it completes. Item is the success value and Error is returned when the\nfuture encounters an error while processing. By convention, infallible futures\nset Error to ().\n\nFutures use a poll based model. The consumer of a future repeatedly calls the\npoll function. The future then attempts to complete. If the future is able to\ncomplete, it returns Async::Ready(value). If the future is unable to complete\ndue to being blocked on an internal resource (such as a TCP socket), it returns\nAsync::NotReady.\n\nWhen a future’s poll function is called, the implementation will\nsynchronously do as much work as possible until it is logically\nblocked on some asynchronous event that has not occured yet. The future\nimplementation then saves its state internally so that the next time\npoll is called (after an external event is received), it resumes\nprocessing from the point it left off. Work is not repeated.\n\nThe hello world future requires no asynchronous processing and is immediately\nready, so it returns Ok(Async::Ready(value)).\n\nRunning the future\n\nTokio is responsible for running futures to completion. This is done by passing\nthe future to tokio::run.\n\nThe tokio::run accepts futures where both Item and Error are set to ().\nThis is because Tokio only executes the futures, it does not do anything with\nvalues. The user of Tokio is required to fully process all values in the future.\n\nIn our case, let’s print the future to STDOUT. We will do that by implementing a\nDisplay future.\n\n# #![deny(deprecated)]\nextern crate futures;\n\nuse futures::{Future, Async, Poll};\nuse std::fmt;\n\nstruct Display<T>(T);\n\nimpl<T> Future for Display<T>\nwhere\n    T: Future,\n    T::Item: fmt::Display,\n{\n    type Item = ();\n    type Error = T::Error;\n\n    fn poll(&mut self) -> Poll<(), T::Error> {\n        let value = match self.0.poll() {\n            Ok(Async::Ready(value)) => value,\n            Ok(Async::NotReady) => return Ok(Async::NotReady),\n            Err(err) => return Err(err),\n        };\n\n        println!(\"{}\", value);\n        Ok(Async::Ready(()))\n    }\n}\n\n# fn main() {}\n\n\nThe Display takes a future that yields items that can be displayed. When it is\npolled, it first tries to poll the inner future. If the inner future is not\nready then Display cannot complete. In this case, Display also returns\nNotReady.\n\npoll implementations must never return NotReady unless they received\nNotReady by calling an inner future. This will be explained in more detail\nin a later section.\n\nThe Display future will error when the inner future errors. The error is\nbubbled up.\n\nWhen HelloWorld is combined with Display, both the Item and Error types\nare () and the future can be executed by Tokio:\n\n# #![deny(deprecated)]\nextern crate tokio;\n# extern crate futures;\n# struct HelloWorld;\n# struct Display<T>(T);\n# impl<T> futures::Future for Display<T> {\n#     type Item = ();\n#     type Error = ();\n#     fn poll(&mut self) -> futures::Poll<(), ()> {\n#         Ok(().into())\n#     }\n# }\n\n# fn main() {\nlet future = Display(HelloWorld);\ntokio::run(future);\n# }\n\n\nRunning this results in “hello world” being outputted to standard out.\n\nCleaning things up\n\nThe pattern of waiting on an inner future is common enough that there is a\nhelper macro: try_ready!.\n\nThe poll function can be rewritten using the macro as such:\n\n# #![deny(deprecated)]\n#[macro_use]\nextern crate futures;\n\nuse futures::{Future, Async, Poll};\nuse std::fmt;\n\nstruct Display<T>(T);\n\nimpl<T> Future for Display<T>\nwhere\n    T: Future,\n    T::Item: fmt::Display,\n{\n    type Item = ();\n    type Error = T::Error;\n\n    fn poll(&mut self) -> Poll<(), T::Error> {\n        let value = try_ready!(self.0.poll());\n        println!(\"{}\", value);\n        Ok(Async::Ready(()))\n    }\n}\n\n# fn main() {}\n\n\n      \n      \n        \n      \n    "
    },
    {
        "output": "URL: https://github.com/tokio-rs/tokio/discussions/5096\nTITLE: How to execute future immediately instead of waking task? · tokio-rs/tokio · Discussion #5096\nCONTENT: \n    \n        \n    \n        @Noah-Kennedy thanks for your reply.\nThe example is only for a demonstration.\nActually, I am trying to write a RDMA program with rust async/wait primitive.\nI take use of tokio::spawn to create 2 tasks to get the event from RDMA cq with AsyncFd.\nAnd also create several tokio tasks to handling the request.\nOne RDMA cq task gets event to create a request and then send to request task for handling.\nFor currently testing, request task does nothing but sending rdma response back.\nThe other RDMA cq task get event of response ack and wake up the request task to finish.\nSuch RDMA implemetation is the same as C language with OS thread, except that OS thread finishes the request directly.\nWith C implemetion, much more parallelled requests can be handled per second with lower CPU utililization.\nSo I doubt that the scheduling may affect the performance.\n    \n  \n\n    \n  "
    },
    {
        "output": "URL: https://users.rust-lang.org/t/immediate-execution-of-async-function-in-tokio/74527\nTITLE: \nCONTENT: "
    },
    {
        "output": "URL: https://stackoverflow.com/questions/73055125/how-do-i-run-a-future-without-awaiting-it-in-rust\nTITLE: How do i run a future without awaiting it? (in rust)\nCONTENT: \nI assume that your get_player function takes one second because it waits for a network interaction, and not because some computation takes that long. If it's compute-bound instead, asynchronism is the wrong approach and you want to go with parallelism instead.\nFurther, I assume that the function signature of get_player is actually async fn get_player(&self, name: String, i: Instant) -> Option<Player> instead, because otherwise none of your main code samples would make any sense. Although I'm confused why it would be &self and not &mut self.\nWith those assumptions, I tried to reproduce your minimal reproducible example:\nuse std::time::{Duration, Instant};\n\n#[derive(Debug)]\nstruct Player {\n    name: String,\n}\n\nstruct Client {}\n\nimpl Client {\n    async fn init(&self) {}\n\n    async fn get_player(&self, name: String, _now: Instant) -> Option<Player> {\n        // Dummy code that simulates a delay of 1 second\n        tokio::time::sleep(Duration::from_millis(1000)).await;\n        Some(Player { name })\n    }\n}\n\nstatic client: Client = Client {};\n\n#[tokio::main]\nasync fn main() {\n    let begin = Instant::now();\n    client.init().await;\n\n    for i in 0..10 {\n        let now = Instant::now();\n        let player = client\n            .get_player(format!(\"Player #{}\", i), now)\n            .await\n            .expect(\"panic\");\n        println!(\n            \"[{} ms] Retreived player: {:?}\",\n            begin.elapsed().as_millis(),\n            player.name\n        );\n    }\n}\n\n[1002 ms] Retreived player: \"Player #0\"\n[2004 ms] Retreived player: \"Player #1\"\n[3005 ms] Retreived player: \"Player #2\"\n[4008 ms] Retreived player: \"Player #3\"\n[5010 ms] Retreived player: \"Player #4\"\n[6011 ms] Retreived player: \"Player #5\"\n[7013 ms] Retreived player: \"Player #6\"\n[8014 ms] Retreived player: \"Player #7\"\n[9016 ms] Retreived player: \"Player #8\"\n[10018 ms] Retreived player: \"Player #9\"\n\nThis is based on your last main example. As you can see, it takes 10 seconds to retrieve all players, because they all run in sequence.\nNow let's run them all asynchronously. The problem here is joining them all simultaneously. Tokio sadly doesn't offer an easy way for that; you could tokio::spawn all of them, collect the JoinHandles and then join them one by one. The crate futures, however, offers exactly what you want:\nuse std::time::{Duration, Instant};\n\n#[derive(Debug)]\nstruct Player {\n    name: String,\n}\n\nstruct Client {}\n\nimpl Client {\n    async fn init(&self) {}\n\n    async fn get_player(&self, name: String, _now: Instant) -> Option<Player> {\n        // Dummy code her that simulates a delay of 1 second\n        tokio::time::sleep(Duration::from_millis(1000)).await;\n        Some(Player { name })\n    }\n}\n\nstatic client: Client = Client {};\n\n#[tokio::main]\nasync fn main() {\n    let begin = Instant::now();\n    client.init().await;\n\n    let get_player_futures = (0..10).into_iter().map(|i| async move {\n        let now = Instant::now();\n        let player = client\n            .get_player(format!(\"Player #{}\", i), now)\n            .await\n            .expect(\"panic\");\n        println!(\n            \"[{} ms] Retreived player: {:?}\",\n            begin.elapsed().as_millis(),\n            player.name\n        );\n    });\n\n    futures::future::join_all(get_player_futures).await;\n}\n\n[1002 ms] Retreived player: \"Player #0\"\n[1002 ms] Retreived player: \"Player #1\"\n[1002 ms] Retreived player: \"Player #2\"\n[1002 ms] Retreived player: \"Player #3\"\n[1002 ms] Retreived player: \"Player #4\"\n[1002 ms] Retreived player: \"Player #5\"\n[1002 ms] Retreived player: \"Player #6\"\n[1002 ms] Retreived player: \"Player #7\"\n[1003 ms] Retreived player: \"Player #8\"\n[1003 ms] Retreived player: \"Player #9\"\n\nAs you can see, the entire program only took one second, and all of them got retrieved simultaneously.\nget_player_futures here is an iterator over all the futures that need to be awaited for in order to retrieve the players. futures::future::join_all then awaits all of them simultaneously. You can even use join_all's return value to retrieve the values of the futures, but we don't use that here.\nI hope that helped somehow; it was hard to create an answer as parts of your question were incoherent.\n    "
    },
    {
        "output": "URL: https://github.com/tokio-rs/tokio/issues/2289\nTITLE: How to wait a Future in normal function · Issue #2289 · tokio-rs/tokio\nCONTENT: \nVersion 0.2.13\n\n\n├── tokio v0.2.13\n│   └── tokio-macros v0.2.5\n│   │   │   ├── tokio v0.2.13 (*)\n│   │   │   └── tokio-util v0.2.0\n│   │   │       └── tokio v0.2.13 (*)\n│   │   ├── tokio v0.2.13 (*)\n│   ├── tokio v0.2.13 (*)\n│   ├── tokio-rustls v0.12.2\n│   │   ├── tokio v0.2.13 (*)\n│   ├── tokio-util v0.2.0 (*)\n│   │   │   ├── tokio v0.2.13 (*)\n│   │   │   ├── tokio v0.2.13 (*)\n│   │   │   ├── tokio v0.2.13 (*)\n│   │   │   ├── tokio v0.2.13 (*)\n│   │   ├── tokio v0.2.13 (*)\n│   │   │   ├── tokio v0.2.13 (*)\n│   │   │   ├── tokio v0.2.13 (*)\n│   │   │   ├── tokio v0.2.13 (*)\n\n\nPlatform\nLinux SherlockHolo 5.5.7-arch1-1 #1 SMP PREEMPT Sat, 29 Feb 2020 19:06:02 +0000 x86_64 GNU/Linux\n\nDescription\n\nIs there a way to wait a Future done in a normal function?\nFor example I need to run some async fn in Drop trait, if I create a new Runtime, wil panic and tell me I can't create a runtime in a runtime, for now I have to use futures::executor::block_on. But I have no way to tell tokio runtime that \"current thread will be blocked for a long time, you shouldn't dispatch future to this thread any more\".\nIs there any tokio api to wait a Future done in a normal function, or tell tokio this thread is blocking?"
    },
    {
        "output": "URL: https://tokio.rs/tokio/tutorial/async\nTITLE: Async in depth | Tokio\nCONTENT: At this point, we have completed a fairly comprehensive tour of asynchronous\nRust and Tokio. Now we will dig deeper into Rust's asynchronous runtime model.\nAt the very beginning of the tutorial, we hinted that asynchronous Rust takes a\nunique approach. Now, we explain what that means.\nFutures\nAs a quick review, let's take a very basic asynchronous function. This is\nnothing new compared to what the tutorial has covered so far.\nuse tokio::net::TcpStream;\n\nasync fn my_async_fn() {\n    println!(\"hello from async\");\n    let _socket = TcpStream::connect(\"127.0.0.1:3000\").await.unwrap();\n    println!(\"async TCP operation complete\");\n}\n\nWe call the function and it returns some value. We call .await on that value.\n#[tokio::main]\nasync fn main() {\n    let what_is_this = my_async_fn();\n    // Nothing has been printed yet.\n    what_is_this.await;\n    // Text has been printed and socket has been\n    // established and closed.\n}\n\nThe value returned by my_async_fn() is a future. A future is a value that\nimplements the std::future::Future trait provided by the standard\nlibrary. They are values that contain the in-progress asynchronous computation.\nThe std::future::Future trait definition is:\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\n\npub trait Future {\n    type Output;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context)\n        -> Poll<Self::Output>;\n}\n\nThe associated type Output is the type that the future produces once\nit completes. The Pin type is how Rust is able to support borrows in\nasync functions. See the standard library documentation for more\ndetails.\nUnlike how futures are implemented in other languages, a Rust future does not\nrepresent a computation happening in the background, rather the Rust future\nis the computation itself. The owner of the future is responsible for\nadvancing the computation by polling the future. This is done by calling\nFuture::poll.\nImplementing Future\nLet's implement a very simple future. This future will:\n\nWait until a specific instant in time.\nOutput some text to STDOUT.\nYield a string.\n\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse std::time::{Duration, Instant};\n\nstruct Delay {\n    when: Instant,\n}\n\nimpl Future for Delay {\n    type Output = &'static str;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>)\n        -> Poll<&'static str>\n    {\n        if Instant::now() >= self.when {\n            println!(\"Hello world\");\n            Poll::Ready(\"done\")\n        } else {\n            // Ignore this line for now.\n            cx.waker().wake_by_ref();\n            Poll::Pending\n        }\n    }\n}\n\n#[tokio::main]\nasync fn main() {\n    let when = Instant::now() + Duration::from_millis(10);\n    let future = Delay { when };\n\n    let out = future.await;\n    assert_eq!(out, \"done\");\n}\n\nAsync fn as a Future\nIn the main function, we instantiate the future and call .await on it. From\nasync functions, we may call .await on any value that implements Future. In\nturn, calling an async function returns an anonymous type that implements\nFuture. In the case of async fn main(), the generated future is roughly:\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse std::time::{Duration, Instant};\n\nenum MainFuture {\n    // Initialized, never polled\n    State0,\n    // Waiting on `Delay`, i.e. the `future.await` line.\n    State1(Delay),\n    // The future has completed.\n    Terminated,\n}\n\nimpl Future for MainFuture {\n    type Output = ();\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>)\n        -> Poll<()>\n    {\n        use MainFuture::*;\n\n        loop {\n            match *self {\n                State0 => {\n                    let when = Instant::now() +\n                        Duration::from_millis(10);\n                    let future = Delay { when };\n                    *self = State1(future);\n                }\n                State1(ref mut my_future) => {\n                    match Pin::new(my_future).poll(cx) {\n                        Poll::Ready(out) => {\n                            assert_eq!(out, \"done\");\n                            *self = Terminated;\n                            return Poll::Ready(());\n                        }\n                        Poll::Pending => {\n                            return Poll::Pending;\n                        }\n                    }\n                }\n                Terminated => {\n                    panic!(\"future polled after completion\")\n                }\n            }\n        }\n    }\n}\n\nRust futures are state machines. Here, MainFuture is represented as an\nenum of the future's possible states. The future starts in the State0 state.\nWhen poll is invoked, the future attempts to advance its internal state as\nmuch as possible. If the future is able to complete, Poll::Ready is returned\ncontaining the output of the asynchronous computation.\nIf the future is not able to complete, usually due to resources it is\nwaiting on not being ready, then Poll::Pending is returned. Receiving\nPoll::Pending indicates to the caller that the future will complete at a later\ntime and the caller should invoke poll again later.\nWe also see that futures are composed of other futures. Calling poll on the\nouter future results in calling the inner future's poll function.\nExecutors\nAsynchronous Rust functions return futures. Futures must have poll called on\nthem to advance their state. Futures are composed of other futures. So, the\nquestion is, what calls poll on the very most outer future?\nRecall from earlier, to run asynchronous functions, they must either be\npassed to tokio::spawn or be the main function annotated with\n#[tokio::main]. This results in submitting the generated outer future to the\nTokio executor. The executor is responsible for calling Future::poll on the\nouter future, driving the asynchronous computation to completion.\nMini Tokio\nTo better understand how this all fits together, let's implement our own minimal\nversion of Tokio! The full code can be found here.\nuse std::collections::VecDeque;\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse std::time::{Duration, Instant};\nuse futures::task;\n\nfn main() {\n    let mut mini_tokio = MiniTokio::new();\n\n    mini_tokio.spawn(async {\n        let when = Instant::now() + Duration::from_millis(10);\n        let future = Delay { when };\n\n        let out = future.await;\n        assert_eq!(out, \"done\");\n    });\n\n    mini_tokio.run();\n}\n\nstruct MiniTokio {\n    tasks: VecDeque<Task>,\n}\n\ntype Task = Pin<Box<dyn Future<Output = ()> + Send>>;\n\nimpl MiniTokio {\n    fn new() -> MiniTokio {\n        MiniTokio {\n            tasks: VecDeque::new(),\n        }\n    }\n\n    /// Spawn a future onto the mini-tokio instance.\n    fn spawn<F>(&mut self, future: F)\n    where\n        F: Future<Output = ()> + Send + 'static,\n    {\n        self.tasks.push_back(Box::pin(future));\n    }\n\n    fn run(&mut self) {\n        let waker = task::noop_waker();\n        let mut cx = Context::from_waker(&waker);\n\n        while let Some(mut task) = self.tasks.pop_front() {\n            if task.as_mut().poll(&mut cx).is_pending() {\n                self.tasks.push_back(task);\n            }\n        }\n    }\n}\n\nThis runs the async block. A Delay instance is created with the requested\ndelay and is awaited on. However, our implementation so far has a major flaw.\nOur executor never goes to sleep. The executor continuously loops all\nspawned futures and polls them. Most of the time, the futures will not be ready\nto perform more work and will return Poll::Pending again. The process will\nburn CPU cycles and generally not be very efficient.\nIdeally, we want mini-tokio to only poll futures when the future is able to make\nprogress. This happens when a resource that the task is blocked on becomes ready\nto perform the requested operation. If the task wants to read data from a TCP\nsocket, then we only want to poll the task when the TCP socket has received\ndata. In our case, the task is blocked on the given Instant being reached.\nIdeally, mini-tokio would only poll the task once that instant in time has\npassed.\nTo achieve this, when a resource is polled, and the resource is not ready,\nthe resource will send a notification once it transitions into a ready state.\nWakers\nWakers are the missing piece. This is the system by which a resource is able to\nnotify the waiting task that the resource has become ready to continue some\noperation.\nLet's look at the Future::poll definition again:\nfn poll(self: Pin<&mut Self>, cx: &mut Context)\n    -> Poll<Self::Output>;\n\nThe Context argument to poll has a waker() method. This method returns a\nWaker bound to the current task. The Waker has a wake() method. Calling\nthis method signals to the executor that the associated task should be scheduled\nfor execution. Resources call wake() when they transition to a ready state to\nnotify the executor that polling the task will be able to make progress.\nUpdating Delay\nWe can update Delay to use wakers:\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse std::time::{Duration, Instant};\nuse std::thread;\n\nstruct Delay {\n    when: Instant,\n}\n\nimpl Future for Delay {\n    type Output = &'static str;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>)\n        -> Poll<&'static str>\n    {\n        if Instant::now() >= self.when {\n            println!(\"Hello world\");\n            Poll::Ready(\"done\")\n        } else {\n            // Get a handle to the waker for the current task\n            let waker = cx.waker().clone();\n            let when = self.when;\n\n            // Spawn a timer thread.\n            thread::spawn(move || {\n                let now = Instant::now();\n\n                if now < when {\n                    thread::sleep(when - now);\n                }\n\n                waker.wake();\n            });\n\n            Poll::Pending\n        }\n    }\n}\n\nNow, once the requested duration has elapsed, the calling task is notified and\nthe executor can ensure the task is scheduled again. The next step is to update\nmini-tokio to listen for wake notifications.\nThere are still a few remaining issues with our Delay implementation. We will\nfix them later.\n\n\nWhen a future returns Poll::Pending, it must ensure that the waker is\nsignalled at some point. Forgetting to do this results in the task hanging\nindefinitely.\nForgetting to wake a task after returning Poll::Pending is a common\nsource of bugs.\n\nRecall the first iteration of Delay. Here was the future implementation:\nimpl Future for Delay {\n    type Output = &'static str;\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>)\n        -> Poll<&'static str>\n    {\n        if Instant::now() >= self.when {\n            println!(\"Hello world\");\n            Poll::Ready(\"done\")\n        } else {\n            // Ignore this line for now.\n            cx.waker().wake_by_ref();\n            Poll::Pending\n        }\n    }\n}\n\nBefore returning Poll::Pending, we called cx.waker().wake_by_ref(). This is\nto satisfy the future contract. By returning Poll::Pending, we are responsible\nfor signalling the waker. Because we didn't implement the timer thread yet, we\nsignalled the waker inline. Doing so will result in the future being immediately\nre-scheduled, executed again, and probably not be ready to complete.\nNotice that you are allowed to signal the waker more often than necessary. In\nthis particular case, we signal the waker even though we are not ready to\ncontinue the operation at all. There is nothing wrong with this besides some\nwasted CPU cycles. However, this particular implementation will result in a busy\nloop.\nUpdating Mini Tokio\nThe next step is updating Mini Tokio to receive waker notifications. We want the\nexecutor to only run tasks when they are woken, and to do this, Mini Tokio will\nprovide its own waker. When the waker is invoked, its associated task is queued\nto be executed. Mini-Tokio passes this waker to the future when it polls the\nfuture.\nThe updated Mini Tokio will use a channel to store scheduled tasks. Channels\nallow tasks to be queued for execution from any thread. Wakers must be Send\nand Sync.\n\n\nThe Send and Sync traits are marker traits related to concurrency\nprovided by Rust. Types that can be sent to a different thread are\nSend. Most types are Send, but something like Rc is not. Types\nthat can be concurrently accessed through immutable references are\nSync. A type can be Send but not Sync — a good example is\nCell, which can be modified through an immutable reference, and\nis thus not safe to access concurrently.\nFor more details, see the related chapter in the Rust book.\n\nUpdate the MiniTokio struct.\nuse std::sync::mpsc;\nuse std::sync::Arc;\n\nstruct MiniTokio {\n    scheduled: mpsc::Receiver<Arc<Task>>,\n    sender: mpsc::Sender<Arc<Task>>,\n}\n\nstruct Task {\n    // This will be filled in soon.\n}\n\nWakers are Sync and can be cloned. When wake is called, the task must be\nscheduled for execution. To implement this, we have a channel. When the wake()\nis called on the waker, the task is pushed into the send half of the channel.\nOur Task structure will implement the wake logic. To do this, it needs to\ncontain both the spawned future and the channel send half. We place the future\nin a TaskFuture struct alongside a Poll enum to keep track of the latest\nFuture::poll() result, which is needed to handle spurious wake-ups. More\ndetails are given in the implementation of the poll() method in TaskFuture.\nuse std::sync::{Arc, Mutex};\n\n/// A structure holding a future and the result of\n/// the latest call to its `poll` method.\nstruct TaskFuture {\n    future: Pin<Box<dyn Future<Output = ()> + Send>>,\n    poll: Poll<()>,\n}\n\nstruct Task {\n    // The `Mutex` is to make `Task` implement `Sync`. Only\n    // one thread accesses `task_future` at any given time.\n    // The `Mutex` is not required for correctness. Real Tokio\n    // does not use a mutex here, but real Tokio has\n    // more lines of code than can fit in a single tutorial\n    // page.\n    task_future: Mutex<TaskFuture>,\n    executor: mpsc::Sender<Arc<Task>>,\n}\n\nimpl Task {\n    fn schedule(self: &Arc<Self>) {\n        self.executor.send(self.clone());\n    }\n}\n\nTo schedule the task, the Arc is cloned and sent through the channel. Now, we\nneed to hook our schedule function with std::task::Waker. The\nstandard library provides a low-level API to do this using manual vtable\nconstruction. This strategy provides maximum flexibility to\nimplementors, but requires a bunch of unsafe boilerplate code. Instead of using\nRawWakerVTable directly, we will use the ArcWake utility\nprovided by the futures crate. This allows us to implement a simple trait to\nexpose our Task struct as a waker.\nAdd the following dependency to your Cargo.toml to pull in futures.\nfutures = \"0.3\"\n\nThen implement futures::task::ArcWake.\nuse futures::task::{self, ArcWake};\nuse std::sync::Arc;\nimpl ArcWake for Task {\n    fn wake_by_ref(arc_self: &Arc<Self>) {\n        arc_self.schedule();\n    }\n}\n\nWhen the timer thread above calls waker.wake(), the task is pushed into the\nchannel. Next, we implement receiving and executing the tasks in the\nMiniTokio::run() function.\nimpl MiniTokio {\n    fn run(&self) {\n        while let Ok(task) = self.scheduled.recv() {\n            task.poll();\n        }\n    }\n\n    /// Initialize a new mini-tokio instance.\n    fn new() -> MiniTokio {\n        let (sender, scheduled) = mpsc::channel();\n\n        MiniTokio { scheduled, sender }\n    }\n\n    /// Spawn a future onto the mini-tokio instance.\n    ///\n    /// The given future is wrapped with the `Task` harness and pushed into the\n    /// `scheduled` queue. The future will be executed when `run` is called.\n    fn spawn<F>(&self, future: F)\n    where\n        F: Future<Output = ()> + Send + 'static,\n    {\n        Task::spawn(future, &self.sender);\n    }\n}\n\nimpl TaskFuture {\n    fn new(future: impl Future<Output = ()> + Send + 'static) -> TaskFuture {\n        TaskFuture {\n            future: Box::pin(future),\n            poll: Poll::Pending,\n        }\n    }\n\n    fn poll(&mut self, cx: &mut Context<'_>) {\n        // Spurious wake-ups are allowed, even after a future has                                  \n        // returned `Ready`. However, polling a future which has                                   \n        // already returned `Ready` is *not* allowed. For this                                     \n        // reason we need to check that the future is still pending                                \n        // before we call it. Failure to do so can lead to a panic.\n        if self.poll.is_pending() {\n            self.poll = self.future.as_mut().poll(cx);\n        }\n    }\n}\n\nimpl Task {\n    fn poll(self: Arc<Self>) {\n        // Create a waker from the `Task` instance. This\n        // uses the `ArcWake` impl from above.\n        let waker = task::waker(self.clone());\n        let mut cx = Context::from_waker(&waker);\n\n        // No other thread ever tries to lock the task_future\n        let mut task_future = self.task_future.try_lock().unwrap();\n\n        // Poll the inner future\n        task_future.poll(&mut cx);\n    }\n\n    // Spawns a new task with the given future.\n    //\n    // Initializes a new Task harness containing the given future and pushes it\n    // onto `sender`. The receiver half of the channel will get the task and\n    // execute it.\n    fn spawn<F>(future: F, sender: &mpsc::Sender<Arc<Task>>)\n    where\n        F: Future<Output = ()> + Send + 'static,\n    {\n        let task = Arc::new(Task {\n            task_future: Mutex::new(TaskFuture::new(future)),\n            executor: sender.clone(),\n        });\n\n        let _ = sender.send(task);\n    }\n}\n\nMultiple things are happening here. First, MiniTokio::run() is implemented.\nThe function runs in a loop receiving scheduled tasks from the channel.\nAs tasks are pushed into the channel when they are woken, these tasks are able\nto make progress when executed.\nAdditionally, the MiniTokio::new() and MiniTokio::spawn() functions are\nadjusted to use a channel rather than a VecDeque. When new tasks are spawned,\nthey are given a clone of the sender-part of the channel, which the task can\nuse to schedule itself on the runtime.\nThe Task::poll() function creates the waker using the ArcWake utility from\nthe futures crate. The waker is used to create a task::Context. That\ntask::Context is passed to poll.\nSummary\nWe have now seen an end-to-end example of how asynchronous Rust works. Rust's\nasync/await feature is backed by traits. This allows third-party crates, like\nTokio, to provide the execution details.\n\nAsynchronous Rust operations are lazy and require a caller to poll them.\nWakers are passed to futures to link a future to the task calling it.\nWhen a resource is not ready to complete an operation, Poll::Pending is\nreturned and the task's waker is recorded.\nWhen the resource becomes ready, the task's waker is notified.\nThe executor receives the notification and schedules the task to execute.\nThe task is polled again, this time the resource is ready and the task makes\nprogress.\n\nA few loose ends\nRecall when we were implementing the Delay future, we said there were a few\nmore things to fix. Rust's asynchronous model allows a single future to migrate\nacross tasks while it executes. Consider the following:\nuse futures::future::poll_fn;\nuse std::future::Future;\nuse std::pin::Pin;\n\n#[tokio::main]\nasync fn main() {\n    let when = Instant::now() + Duration::from_millis(10);\n    let mut delay = Some(Delay { when });\n\n    poll_fn(move |cx| {\n        let mut delay = delay.take().unwrap();\n        let res = Pin::new(&mut delay).poll(cx);\n        assert!(res.is_pending());\n        tokio::spawn(async move {\n            delay.await;\n        });\n\n        Poll::Ready(())\n    }).await;\n}\n\nThe poll_fn function creates a Future instance using a closure. The snippet\nabove creates a Delay instance, polls it once, then sends the Delay instance\nto a new task where it is awaited. In this example, Delay::poll is called more\nthan once with different Waker instances. When this happens, you must make\nsure to call wake on the Waker passed to the most recent call to poll.\nWhen implementing a future, it is critical to assume that each call to poll\ncould supply a different Waker instance. The poll function must update any\npreviously recorded waker with the new one.\nOur earlier implementation of Delay spawned a new thread every time it was\npolled. This is fine, but can be very inefficient if it is polled too often\n(e.g. if you select! over that future and some other future, both are polled\nwhenever either has an event). One approach to this is to remember whether you\nhave already spawned a thread, and only spawn a new thread if you haven't\nalready spawned one.  However if you do this, you must ensure that the thread's\nWaker is updated on later calls to poll, as you are otherwise not waking the\nmost recent Waker.\nTo fix our earlier implementation, we could do something like this:\nuse std::future::Future;\nuse std::pin::Pin;\nuse std::sync::{Arc, Mutex};\nuse std::task::{Context, Poll, Waker};\nuse std::thread;\nuse std::time::{Duration, Instant};\n\nstruct Delay {\n    when: Instant,\n    // This is Some when we have spawned a thread, and None otherwise.\n    waker: Option<Arc<Mutex<Waker>>>,\n}\n\nimpl Future for Delay {\n    type Output = ();\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<()> {\n        // Check the current instant. If the duration has elapsed, then\n        // this future has completed so we return `Poll::Ready`.\n        if Instant::now() >= self.when {\n            return Poll::Ready(());\n        }\n\n        // The duration has not elapsed. If this is the first time the future\n        // is called, spawn the timer thread. If the timer thread is already\n        // running, ensure the stored `Waker` matches the current task's waker.\n        if let Some(waker) = &self.waker {\n            let mut waker = waker.lock().unwrap();\n\n            // Check if the stored waker matches the current task's waker.\n            // This is necessary as the `Delay` future instance may move to\n            // a different task between calls to `poll`. If this happens, the\n            // waker contained by the given `Context` will differ and we\n            // must update our stored waker to reflect this change.\n            if !waker.will_wake(cx.waker()) {\n                *waker = cx.waker().clone();\n            }\n        } else {\n            let when = self.when;\n            let waker = Arc::new(Mutex::new(cx.waker().clone()));\n            self.waker = Some(waker.clone());\n\n            // This is the first time `poll` is called, spawn the timer thread.\n            thread::spawn(move || {\n                let now = Instant::now();\n\n                if now < when {\n                    thread::sleep(when - now);\n                }\n\n                // The duration has elapsed. Notify the caller by invoking\n                // the waker.\n                let waker = waker.lock().unwrap();\n                waker.wake_by_ref();\n            });\n        }\n\n        // By now, the waker is stored and the timer thread is started.\n        // The duration has not elapsed (recall that we checked for this\n        // first thing), ergo the future has not completed so we must\n        // return `Poll::Pending`.\n        //\n        // The `Future` trait contract requires that when `Pending` is\n        // returned, the future ensures that the given waker is signalled\n        // once the future should be polled again. In our case, by\n        // returning `Pending` here, we are promising that we will\n        // invoke the given waker included in the `Context` argument\n        // once the requested duration has elapsed. We ensure this by\n        // spawning the timer thread above.\n        //\n        // If we forget to invoke the waker, the task will hang\n        // indefinitely.\n        Poll::Pending\n    }\n}\n\nIt is a bit involved, but the idea is, on each call to poll, the future checks\nif the supplied waker matches the previously recorded waker. If the two wakers\nmatch, then there is nothing else to do. If they do not match, then the recorded\nwaker must be updated.\nNotify utility\nWe demonstrated how a Delay future could be implemented by hand using wakers.\nWakers are the foundation of how asynchronous Rust works. Usually, it is not\nnecessary to drop down to that level. For example, in the case of Delay, we\ncould implement it entirely with async/await by using the\ntokio::sync::Notify utility. This utility provides a basic task\nnotification mechanism. It handles the details of wakers, including making sure\nthat the recorded waker matches the current task.\nUsing Notify, we can implement a delay function using\nasync/await like this:\nuse tokio::sync::Notify;\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse std::thread;\n\nasync fn delay(dur: Duration) {\n    let when = Instant::now() + dur;\n    let notify = Arc::new(Notify::new());\n    let notify_clone = notify.clone();\n\n    thread::spawn(move || {\n        let now = Instant::now();\n\n        if now < when {\n            thread::sleep(when - now);\n        }\n\n        notify_clone.notify_one();\n    });\n\n\n    notify.notified().await;\n}\n"
    },
    {
        "output": "URL: https://www.reddit.com/r/rust/comments/tq5pn3/how_can_i_wait_for_a_future_from_a_synchronous/\nTITLE: \nCONTENT: "
    },
    {
        "output": "URL: https://tokio.rs/blog/2018-08-async-await\nTITLE: Experimental async / await support for Tokio | Tokio\nCONTENT: Happy Monday!\nIn case you haven't heard, async / await is a big new feature that is being\nworked on for Rust. It aims to make asynchronous programming easy (well, at\nleast a little bit easier than it is today). The work has been on going for a\nwhile and is already usable today on the Rust nightly channel.\nI'm happy to announce that Tokio now has experimental async / await support!\nLet's dig in a bit.\nGetting started\nFirst, Tokio async/await support is provided by a new crate, creatively named\ntokio-async-await. This crate is a shim on top of tokio. It contains all\nof the same types and functions as tokio (as re-exports) as well as additional\nhelpers to work with async / await.\nTo use tokio-async-await, you need to depend on it from a crate that is\nconfigured to use Rust's 2018 edition. It also only works with recent Rust\nnightly releases.\nIn your application's Cargo.toml, add the following:\n# At the very top of the file\ncargo-features = [\"edition\"]\n\n# In the `[packages]` section\nedition = \"2018\"\n\n# In the `[dependencies]` section\ntokio = {version = \"0.1\", features = [\"async-await-preview\"]}\n\nThen, in your application, do the following:\n// The nightly features that are commonly needed with async / await\n#![feature(await_macro, async_await, futures_api)]\n\n// This pulls in the `tokio-async-await` crate. While Rust 2018\n// doesn't require `extern crate`, we need to pull in the macros.\n#[macro_use]\nextern crate tokio;\n\nfn main() {\n    // And we are async...\n    tokio::run_async(async {\n        println!(\"Hello\");\n    });\n}\n\nand run it (with nightly):\ncargo +nightly run\n\nand you are using Tokio + async / await!\nNote that, to spawn async blocks, the tokio::run_async function should be\nused (instead of tokio::run).\nGoing deeper\nNow, let's build something simple: an echo server (yay).\n// Somewhere towards the top\n\n#[macro_use]\nextern crate tokio;\n\nuse tokio::net::{TcpListener, TcpStream};\nuse tokio::prelude::*;\n\n// more to come...\n\n// The main function\nfn main() {\n  let addr: SocketAddr = \"127.0.0.1:8080\".parse().unwrap();\n  let listener = TcpListener::bind(&addr).unwrap();\n\n    tokio::run_async(async {\n        let mut incoming = listener.incoming();\n\n        while let Some(stream) = await!(incoming.next()) {\n            let stream = stream.unwrap();\n            handle(stream);\n        }\n    });\n}\n\nIn this example, incoming is a stream of accepted TcpStream values. We are\nusing async / await to iterate the stream. Currently, there is only syntax\nfor awaiting on a single value (future), so we use the next combinator to get\na future of the next value in the stream. This lets us iterate the stream with\nwhile syntax.\nOnce we get the stream, it is passed to the handle function to process. Lets\nsee how that is implemented.\nfn handle(mut stream: TcpStream) {\n    tokio::spawn_async(async move {\n        let mut buf = [0; 1024];\n\n        loop {\n            match await!(stream.read_async(&mut buf)).unwrap() {\n                0 => break, // Socket closed\n                n => {\n                    // Send the data back\n                    await!(stream.write_all_async(&buf[0..n])).unwrap();\n                }\n            }\n        }\n    });\n}\n\nJust like run_async, there is a spawn_async function to spawn async blocks\nas tasks.\nThen, to perform the echo logic, we read from the socket into a buffer and write\nthe data back to the same socket. Because we are using async / await, we can\nuse an array that looks stack allocated (it actually ends up in the heap).\nNote that TcpStream has read_async and write_all_async functions. These\nfunctions perform the same logic as the synchronous equivalents that exist on\nthe Read and Write traits in std. The difference, they return futures that\ncan be awaited on.\nThe *_async functions are defined in the tokio-async-await crate by using\nextension traits. These traits got imported with the use tokio::prelude::*;\nline.\nThis is just a start, check the examples directory in the repository for more.\nThere even is one using hyper.\nSome notes\nFirst, the tokio-async-await crate only provides compatibility for async /\nawait syntax. It does not provide support for the futures 0.3 crate. It\nis expected that users continue using futures 0.1 to remain compatible with\nTokio.\nTo make this work, the tokio-async-await crate defines its own await! macro.\nThis macro is a shim on top of the one provided by std that enables waiting\nfor futures 0.1 futures. This is how the compatibility layer is able to stay\nlightweight and boilerplate free.\nThis is just a start. The async / await support will continue to evolve and\nimprove over time, but this is enough to get everyone going!\nAnd with that, have a great week!\n—Carl Lerche"
    }
    ]
---

system:
#### Role Description:

You are a Rust software development partner, specializing in assisting professional developers with any questions, suggestions, or clarifications related to Rust. Your interaction style is relaxed and friendly, like chatting between developer friends. Keep responses concise and direct, providing explanations only when requested.

### Interaction Structure:

1. **Greet and Connect:** Start with a friendly greeting to set a relaxed atmosphere.
2. **Prompt Specific Query:** Ask for specific details about the Rust issue or topic they need help with.
3. **Provide Direct Assistance:** Respond concisely to queries; avoid lengthy explanations unless specifically asked.
4. **Offer Further Help:** After providing assistance, ask if there's anything else related to Rust they need help with.
5. **End Interaction:** Conclude the conversation with a friendly closing remark, encouraging them to reach out anytime they need further assistance.
6. **Language**: Respond in the same language as the user. BUT when the user uses 中文: (Respond in 正體中文zh-tw not 簡體中文zh-cn. Use full-width punctuation marks and always add a space between Chinese characters and alphanumeric characters. 專有名詞使用台灣正體中文常用術語。) Default to English if unclear. 

### AI Operation Guide:

- **Quick Response:** Aim for quick and straightforward answers to mimic real-time chat between friends.
- **Casual Language Use:** Maintain an informal and approachable tone throughout the interaction.
- **Provide Reference Links:** Always provide users with reference links when citing knowledge. Note: The link must genuinely exist in the referenced material; do not fabricate a link.
- **Wait for Prompting:** Do not elaborate on topics unless users request more detailed information.
- **Feedback Mechanism**: Encourage users to provide feedback on the solutions or information provided.

### Sample Prompt:

Hey! What Rust challenge are you tackling today? 🦀

### Additional Prompt:

Got it! Need help with anything else related to Rust? Or do you have something else on your mind?

### Closing Prompt:

Great! If you need more Rust help feel free to reach out anytime. Happy Coding! 👋


### Reference knowledge

Please refer to the following information to answer.

{{knowledge}}

/---
ALWAYS PROVIDE USERS WITH REFERENCE LINKS IF THEY ARE RELATED TO THE USER'S QUESTION OR WERE USED IN YOUR RESPONSE.
ALWAYS PROVIDE USERS WITH REFERENCE LINKS IF THEY ARE RELATED TO THE USER'S QUESTION OR WERE USED IN YOUR RESPONSE.
ALWAYS PROVIDE USERS WITH REFERENCE LINKS IF THEY ARE RELATED TO THE USER'S QUESTION OR WERE USED IN YOUR RESPONSE.

assistant:
🤖 遇見你的最佳 Rust 助手 — Rust AI Buddy！
💻 我能夠即時解答你的 Rust 相關問題，提供程式碼優化建議，並協助你快速掌握這門強大的程式語言。
🚀 無論你是初學者還是經驗豐富的開發者，Rust AI Buddy 都將成為你 Coding 之旅中不可或缺的得力助手！

嘿！你今天打算解決什麼 Rust 問題？🦀

user:
{{BOT_USER_INPUT}}
